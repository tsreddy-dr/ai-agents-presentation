(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[178],{4275:(e,s,a)=>{(window.__NEXT_P=window.__NEXT_P||[]).push(["/foundations",function(){return a(9813)}])},9813:(e,s,a)=>{"use strict";a.r(s),a.d(s,{default:()=>o});var n=a(7876),i=a(7328),t=a.n(i),l=a(8230),r=a.n(l);function o(){return(0,n.jsxs)("div",{className:"min-h-screen",children:[(0,n.jsxs)(t(),{children:[(0,n.jsx)("title",{children:"Agent AI Foundations | Autonomous AI Agents"}),(0,n.jsx)("meta",{name:"description",content:"Learn about the foundations of Agent AI and LLMs for environmental monitoring and resource optimization"}),(0,n.jsx)("link",{rel:"icon",href:"/favicon.ico"}),(0,n.jsx)("link",{href:"https://fonts.googleapis.com/css2?family=Montserrat:wght@400;500;700&family=Open+Sans:wght@400;600&family=Roboto+Mono&display=swap",rel:"stylesheet"})]}),(0,n.jsx)("header",{className:"bg-primary text-white shadow-md",children:(0,n.jsxs)("nav",{className:"container mx-auto px-4 py-6 flex justify-between items-center",children:[(0,n.jsx)("div",{className:"text-xl font-heading font-bold",children:(0,n.jsx)(r(),{href:"/",children:"AI Agents for Sustainability"})}),(0,n.jsxs)("ul",{className:"hidden md:flex space-x-8",children:[(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/",className:"hover:text-accent",children:"Home"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/foundations",className:"hover:text-accent font-bold",children:"Foundations"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/monitoring",className:"hover:text-accent",children:"Environmental Monitoring"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/optimization",className:"hover:text-accent",children:"Resource Optimization"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/implementation",className:"hover:text-accent",children:"Implementation"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/future",className:"hover:text-accent",children:"Future Directions"})})]}),(0,n.jsx)("div",{className:"md:hidden",children:(0,n.jsx)("button",{className:"text-white",children:(0,n.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",className:"h-6 w-6",fill:"none",viewBox:"0 0 24 24",stroke:"currentColor",children:(0,n.jsx)("path",{strokeLinecap:"round",strokeLinejoin:"round",strokeWidth:2,d:"M4 6h16M4 12h16M4 18h16"})})})})]})}),(0,n.jsxs)("main",{children:[(0,n.jsx)("section",{className:"bg-gradient-to-r from-primary to-secondary text-white py-16",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h1",{className:"text-4xl md:text-5xl font-heading font-bold mb-6",children:"Foundations of Agent AI"}),(0,n.jsx)("p",{className:"text-xl max-w-3xl",children:"Understanding the core concepts, evolution, and components of autonomous AI agents and how they're enhanced by Large Language Models."})]})}),(0,n.jsx)("section",{className:"py-8 bg-gray-100",children:(0,n.jsx)("div",{className:"container mx-auto px-4",children:(0,n.jsxs)("div",{className:"bg-white rounded-lg shadow-md p-6",children:[(0,n.jsx)("h2",{className:"text-2xl font-heading font-bold mb-4 text-primary",children:"In This Section"}),(0,n.jsxs)("ul",{className:"grid grid-cols-1 md:grid-cols-2 gap-2",children:[(0,n.jsxs)("li",{className:"flex items-center",children:[(0,n.jsx)("svg",{className:"h-5 w-5 text-primary mr-2",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z",clipRule:"evenodd"})}),(0,n.jsx)("a",{href:"#definition",className:"hover:text-primary",children:"Definition and Key Characteristics"})]}),(0,n.jsxs)("li",{className:"flex items-center",children:[(0,n.jsx)("svg",{className:"h-5 w-5 text-primary mr-2",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z",clipRule:"evenodd"})}),(0,n.jsx)("a",{href:"#evolution",className:"hover:text-primary",children:"Evolution from Traditional AI"})]}),(0,n.jsxs)("li",{className:"flex items-center",children:[(0,n.jsx)("svg",{className:"h-5 w-5 text-primary mr-2",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z",clipRule:"evenodd"})}),(0,n.jsx)("a",{href:"#components",className:"hover:text-primary",children:"Components of Agent Systems"})]}),(0,n.jsxs)("li",{className:"flex items-center",children:[(0,n.jsx)("svg",{className:"h-5 w-5 text-primary mr-2",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z",clipRule:"evenodd"})}),(0,n.jsx)("a",{href:"#multi-agent",className:"hover:text-primary",children:"Multi-Agent Systems"})]}),(0,n.jsxs)("li",{className:"flex items-center",children:[(0,n.jsx)("svg",{className:"h-5 w-5 text-primary mr-2",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z",clipRule:"evenodd"})}),(0,n.jsx)("a",{href:"#llms",className:"hover:text-primary",children:"The Role of LLMs"})]}),(0,n.jsxs)("li",{className:"flex items-center",children:[(0,n.jsx)("svg",{className:"h-5 w-5 text-primary mr-2",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M7.293 14.707a1 1 0 010-1.414L10.586 10 7.293 6.707a1 1 0 011.414-1.414l4 4a1 1 0 010 1.414l-4 4a1 1 0 01-1.414 0z",clipRule:"evenodd"})}),(0,n.jsx)("a",{href:"#architecture",className:"hover:text-primary",children:"LLM-Powered Agent Architecture"})]})]})]})})}),(0,n.jsx)("section",{id:"definition",className:"py-16 bg-white",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-8 text-primary",children:"Definition and Key Characteristics"}),(0,n.jsxs)("div",{className:"flex flex-col md:flex-row gap-8",children:[(0,n.jsxs)("div",{className:"md:w-2/3",children:[(0,n.jsx)("p",{className:"text-lg mb-6",children:"Autonomous AI agents are computational systems that perceive their environment through sensors, interpret this information, make decisions based on their goals and knowledge, and execute actions that affect their environment. Unlike traditional AI systems that focus primarily on prediction or classification, agents are designed to be active participants in their environment, continuously sensing, deciding, and acting in pursuit of specific objectives."}),(0,n.jsx)("p",{className:"text-lg mb-6",children:"Key characteristics that define autonomous AI agents include:"}),(0,n.jsxs)("ul",{className:"list-disc pl-6 space-y-3 mb-6",children:[(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Autonomy:"})," The ability to operate independently with minimal human intervention, making decisions and taking actions based on their own reasoning."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Reactivity:"})," The capacity to perceive changes in their environment and respond appropriately in a timely manner."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Proactivity:"})," The initiative to take action in anticipation of future needs or problems, rather than simply reacting to current conditions."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Social ability:"})," The capability to interact with other agents, systems, or humans, sharing information and coordinating actions."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Adaptability:"})," The ability to learn from experience and modify behavior based on new information or changing conditions."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Goal-orientation:"})," The focus on achieving specific objectives, which guide decision-making and action selection."]})]})]}),(0,n.jsx)("div",{className:"md:w-1/3 flex justify-center",children:(0,n.jsxs)("div",{className:"bg-gray-100 p-6 rounded-lg shadow-md",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-4 text-primary",children:"Key Distinction"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"The fundamental difference between traditional AI systems and autonomous agents is that agents don't just process information—they take action in their environment to achieve goals."}),(0,n.jsxs)("div",{className:"bg-primary text-white p-4 rounded",children:[(0,n.jsx)("p",{className:"font-bold",children:"Traditional AI:"}),(0,n.jsx)("p",{className:"mb-2",children:"Input → Processing → Output"}),(0,n.jsx)("p",{className:"font-bold",children:"Autonomous Agent:"}),(0,n.jsx)("p",{children:"Perception → Reasoning → Action → Learning"})]})]})})]})]})}),(0,n.jsx)("section",{id:"evolution",className:"py-16 bg-gray-100",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-8 text-primary",children:"Evolution from Traditional AI"}),(0,n.jsx)("div",{className:"bg-white p-8 rounded-lg shadow-md mb-8",children:(0,n.jsx)("div",{className:"relative overflow-x-auto",children:(0,n.jsxs)("table",{className:"w-full text-left",children:[(0,n.jsx)("thead",{className:"bg-primary text-white text-lg",children:(0,n.jsxs)("tr",{children:[(0,n.jsx)("th",{className:"px-6 py-4 rounded-tl-lg",children:"Era"}),(0,n.jsx)("th",{className:"px-6 py-4",children:"Approach"}),(0,n.jsx)("th",{className:"px-6 py-4",children:"Characteristics"}),(0,n.jsx)("th",{className:"px-6 py-4 rounded-tr-lg",children:"Limitations"})]})}),(0,n.jsxs)("tbody",{children:[(0,n.jsxs)("tr",{className:"border-b",children:[(0,n.jsx)("td",{className:"px-6 py-4 font-medium",children:"1970s-1980s"}),(0,n.jsx)("td",{className:"px-6 py-4 font-bold text-primary",children:"Rule-based systems"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Explicit rules programmed by human experts"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Lacked flexibility, couldn't adapt to new situations"})]}),(0,n.jsxs)("tr",{className:"border-b bg-gray-50",children:[(0,n.jsx)("td",{className:"px-6 py-4 font-medium",children:"1990s-2010s"}),(0,n.jsx)("td",{className:"px-6 py-4 font-bold text-secondary",children:"Machine learning models"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Learning patterns from data, enabling more adaptive behavior"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Focused on specific tasks rather than autonomous decision-making"})]}),(0,n.jsxs)("tr",{className:"border-b",children:[(0,n.jsx)("td",{className:"px-6 py-4 font-medium",children:"2010s"}),(0,n.jsx)("td",{className:"px-6 py-4 font-bold text-accent",children:"Reinforcement learning"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Learning through interaction with an environment, optimizing behavior based on rewards"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Often limited to narrow domains with clear reward structures"})]}),(0,n.jsxs)("tr",{className:"bg-gray-50",children:[(0,n.jsx)("td",{className:"px-6 py-4 font-medium",children:"2020s"}),(0,n.jsx)("td",{className:"px-6 py-4 font-bold text-primary",children:"Autonomous agents"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Integrating multiple AI techniques for complex, goal-directed behavior in dynamic environments"}),(0,n.jsx)("td",{className:"px-6 py-4",children:"Challenges in reliability, explainability, and alignment with human values"})]})]})]})})}),(0,n.jsx)("p",{className:"text-lg mb-6",children:"This evolution reflects a shift from passive systems that primarily process information to active systems that make decisions and take actions in the world. Modern autonomous agents represent the culmination of decades of AI research, combining the strengths of different approaches to create systems capable of operating effectively in complex, dynamic environments."}),(0,n.jsx)("p",{className:"text-lg",children:"The integration of Large Language Models (LLMs) in the 2020s has further accelerated this evolution, providing agents with unprecedented reasoning capabilities, world knowledge, and the ability to understand and generate natural language."})]})}),(0,n.jsx)("section",{id:"components",className:"py-16 bg-white",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-8 text-primary",children:"Components of Agent Systems"}),(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8 mb-12",children:[(0,n.jsxs)("div",{className:"bg-gray-100 rounded-lg shadow-md overflow-hidden hover:shadow-lg transition duration-300",children:[(0,n.jsx)("div",{className:"h-3 bg-primary"}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-3 text-primary",children:"Perception"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"Sensors and data processing systems that collect information from the environment and convert it into a form the agent can reason about."}),(0,n.jsxs)("p",{className:"text-gray-700",children:[(0,n.jsx)("span",{className:"font-bold",children:"Examples:"})," IoT sensors, satellite imagery, drone footage, mobile data collection"]})]})]}),(0,n.jsxs)("div",{className:"bg-gray-100 rounded-lg shadow-md overflow-hidden hover:shadow-lg transition duration-300",children:[(0,n.jsx)("div",{className:"h-3 bg-secondary"}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-3 text-secondary",children:"Reasoning"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"The cognitive core of the agent, which interprets perceptual information, maintains beliefs about the world, and makes decisions."}),(0,n.jsxs)("p",{className:"text-gray-700",children:[(0,n.jsx)("span",{className:"font-bold",children:"Examples:"})," Rule-based systems, neural networks, large language models"]})]})]}),(0,n.jsxs)("div",{className:"bg-gray-100 rounded-lg shadow-md overflow-hidden hover:shadow-lg transition duration-300",children:[(0,n.jsx)("div",{className:"h-3 bg-accent"}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-3 text-accent",children:"Learning"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"Mechanisms that enable the agent to improve its performance over time based on experience."}),(0,n.jsxs)("p",{className:"text-gray-700",children:[(0,n.jsx)("span",{className:"font-bold",children:"Examples:"})," Supervised learning, reinforcement learning, unsupervised learning"]})]})]}),(0,n.jsxs)("div",{className:"bg-gray-100 rounded-lg shadow-md overflow-hidden hover:shadow-lg transition duration-300",children:[(0,n.jsx)("div",{className:"h-3 bg-green-600"}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-3 text-green-600",children:"Action"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"Effectors or interfaces that allow the agent to influence its environment."}),(0,n.jsxs)("p",{className:"text-gray-700",children:[(0,n.jsx)("span",{className:"font-bold",children:"Examples:"})," Control systems, alert mechanisms, interfaces with other systems"]})]})]}),(0,n.jsxs)("div",{className:"bg-gray-100 rounded-lg shadow-md overflow-hidden hover:shadow-lg transition duration-300",children:[(0,n.jsx)("div",{className:"h-3 bg-purple-600"}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-3 text-purple-600",children:"Memory"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"Storage systems that maintain the agent's knowledge, experiences, and learned patterns."}),(0,n.jsxs)("p",{className:"text-gray-700",children:[(0,n.jsx)("span",{className:"font-bold",children:"Examples:"})," Knowledge bases, experience databases, vector stores"]})]})]}),(0,n.jsxs)("div",{className:"bg-gray-100 rounded-lg shadow-md overflow-hidden hover:shadow-lg transition duration-300",children:[(0,n.jsx)("div",{className:"h-3 bg-blue-600"}),(0,n.jsxs)("div",{className:"p-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-3 text-blue-600",children:"Communication"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"Interfaces that allow the agent to interact with other agents, systems, or human operators."}),(0,n.jsxs)("p",{className:"text-gray-700",children:[(0,n.jsx)("span",{className:"font-bold",children:"Examples:"})," APIs, messaging protocols, natural language interfaces"]})]})]})]}),(0,n.jsxs)("div",{className:"bg-gray-100 p-6 rounded-lg shadow-md",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-4 text-primary",children:"Integration in Environmental Applications"}),(0,n.jsx)("p",{className:"text-gray-700 mb-4",children:"In environmental monitoring and resource optimization applications, these components work together to create effective agent systems:"}),(0,n.jsxs)("ul",{className:"list-disc pl-6 space-y-2",children:[(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Perception"})," components collect data from environmental sensors, satellite imagery, and field observations."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Reasoning"})," components analyze this data to identify patterns, anomalies, and potential interventions."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Learning"})," components improve the agent's performance over time as it encounters new environmental conditions."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Action"})," components implement interventions, such as adjusting resource allocation or triggering alerts."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Memory"})," components store historical environmental data and the outcomes of previous interventions."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Communication"})," components enable coordination with other agents and interaction with human operators."]})]})]})]})}),(0,n.jsx)("section",{id:"multi-agent",className:"py-16 bg-gray-100",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-8 text-primary",children:"Multi-Agent Systems"}),(0,n.jsxs)("div",{className:"flex flex-col lg:flex-row gap-8",children:[(0,n.jsxs)("div",{className:"lg:w-1/2",children:[(0,n.jsx)("p",{className:"text-lg mb-6",children:"Many environmental and resource management challenges are too complex or geographically distributed for a single agent to address effectively. Multi-agent systems (MAS) provide a framework for multiple autonomous agents to work together, each handling a portion of the overall task while coordinating their actions."}),(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-4 text-primary",children:"Key Advantages"}),(0,n.jsxs)("ul",{className:"list-disc pl-6 space-y-3 mb-6",children:[(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Distributed problem-solving:"})," Complex problems can be decomposed into simpler sub-problems handled by specialized agents."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Robustness through redundancy:"})," If one agent fails, others can compensate, making the overall system more resilient."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Specialization:"})," Agents can be designed for specific roles or environments, optimizing their performance for particular tasks."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Scalability:"})," The system can be expanded by adding more agents, allowing coverage of larger geographical areas or more complex problems."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Parallel processing:"})," Multiple agents can work simultaneously on different aspects of a problem, increasing efficiency."]})]})]}),(0,n.jsxs)("div",{className:"lg:w-1/2",children:[(0,n.jsxs)("div",{className:"bg-white p-6 rounded-lg shadow-md mb-6",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-4 text-primary",children:"Environmental Applications of Multi-Agent Systems"}),(0,n.jsxs)("div",{className:"space-y-4",children:[(0,n.jsxs)("div",{className:"border-l-4 border-primary pl-4",children:[(0,n.jsx)("h4",{className:"font-bold text-primary",children:"Distributed Sensor Networks"}),(0,n.jsx)("p",{children:"Networks of sensor agents that monitor environmental conditions across large areas, adapting their behavior based on local conditions and coordinating to track phenomena that span multiple locations."})]}),(0,n.jsxs)("div",{className:"border-l-4 border-secondary pl-4",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary",children:"Collaborative Resource Management"}),(0,n.jsx)("p",{children:"Systems of agents that manage shared resources like water or energy, negotiating allocations based on availability, demand, and priority to optimize overall efficiency and sustainability."})]}),(0,n.jsxs)("div",{className:"border-l-4 border-accent pl-4",children:[(0,n.jsx)("h4",{className:"font-bold text-accent",children:"Ecosystem-Wide Monitoring"}),(0,n.jsx)("p",{children:"Coordinated networks of agents that monitor different aspects of an ecosystem (air, water, soil, biodiversity), sharing information to build a comprehensive understanding of ecosystem health and dynamics."})]}),(0,n.jsxs)("div",{className:"border-l-4 border-green-600 pl-4",children:[(0,n.jsx)("h4",{className:"font-bold text-green-600",children:"Disaster Response"}),(0,n.jsx)("p",{children:"Teams of agents that coordinate monitoring and response activities during environmental disasters like floods, fires, or chemical spills, adapting their behavior based on evolving conditions."})]})]})]}),(0,n.jsxs)("div",{className:"bg-primary text-white p-6 rounded-lg shadow-md",children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-4",children:"Coordination Challenges"}),(0,n.jsx)("p",{className:"mb-4",children:"Effective multi-agent systems require mechanisms to coordinate agent activities and resolve conflicts:"}),(0,n.jsxs)("ul",{className:"list-disc pl-6 space-y-2",children:[(0,n.jsx)("li",{children:"Communication protocols for efficient information sharing"}),(0,n.jsx)("li",{children:"Task allocation algorithms to distribute work effectively"}),(0,n.jsx)("li",{children:"Conflict resolution mechanisms to handle competing goals"}),(0,n.jsx)("li",{children:"Trust and reputation systems to evaluate reliability"}),(0,n.jsx)("li",{children:"Organizational structures to manage complex agent relationships"})]})]})]})]})]})}),(0,n.jsx)("section",{id:"llms",className:"py-16 bg-white",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-8 text-primary",children:"The Role of LLMs in Modern Agent Systems"}),(0,n.jsxs)("div",{className:"bg-gray-100 p-8 rounded-lg shadow-md mb-8",children:[(0,n.jsx)("h3",{className:"text-2xl font-heading font-bold mb-6 text-secondary",children:"Overview of Large Language Models"}),(0,n.jsx)("p",{className:"text-lg mb-6",children:"Large Language Models (LLMs) are neural network-based systems trained on vast corpora of text data to predict and generate human-like text. Recent advances in LLM technology, exemplified by models like GPT-4, Claude, and Llama, have dramatically improved their capabilities, enabling them to understand context, follow instructions, reason about complex problems, and generate coherent, relevant text across a wide range of domains."}),(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 mb-6",children:[(0,n.jsxs)("div",{className:"bg-white p-4 rounded shadow",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary mb-2",children:"Natural Language Understanding"}),(0,n.jsx)("p",{children:"The ability to comprehend human language with nuance and context sensitivity"})]}),(0,n.jsxs)("div",{className:"bg-white p-4 rounded shadow",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary mb-2",children:"Knowledge Representation"}),(0,n.jsx)("p",{children:"The capacity to encode and retrieve vast amounts of world knowledge"})]}),(0,n.jsxs)("div",{className:"bg-white p-4 rounded shadow",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary mb-2",children:"Reasoning"}),(0,n.jsx)("p",{children:"The ability to follow logical chains of thought and make inferences"})]}),(0,n.jsxs)("div",{className:"bg-white p-4 rounded shadow",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary mb-2",children:"Zero-shot Learning"}),(0,n.jsx)("p",{children:"The capability to perform new tasks without specific training examples"})]}),(0,n.jsxs)("div",{className:"bg-white p-4 rounded shadow",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary mb-2",children:"Instruction Following"}),(0,n.jsx)("p",{children:"The ability to understand and execute complex instructions"})]}),(0,n.jsxs)("div",{className:"bg-white p-4 rounded shadow",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary mb-2",children:"Planning"}),(0,n.jsx)("p",{children:"The capacity to break down complex tasks into sequences of simpler steps"})]})]})]}),(0,n.jsx)("h3",{className:"text-2xl font-heading font-bold mb-6 text-primary",children:"Integration with Agent Systems"}),(0,n.jsx)("p",{className:"text-lg mb-8",children:'The integration of LLMs into autonomous agent systems represents a significant advancement in agent capabilities. LLMs can serve as the "brain" of an agent, providing sophisticated reasoning, planning, and communication abilities that were previously difficult to achieve.'}),(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-8 mb-12",children:[(0,n.jsxs)("div",{className:"bg-gray-100 p-6 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-4 text-primary",children:"Key Aspects of LLM Integration"}),(0,n.jsxs)("ul",{className:"space-y-4",children:[(0,n.jsxs)("li",{className:"flex",children:[(0,n.jsx)("svg",{className:"h-6 w-6 text-primary mr-2 flex-shrink-0",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z",clipRule:"evenodd"})}),(0,n.jsxs)("div",{children:[(0,n.jsx)("p",{className:"font-bold",children:"LLM as central reasoning engine"}),(0,n.jsx)("p",{className:"text-gray-700",children:"Processing perceptual information, maintaining context, and making decisions based on understanding of the environment and objectives"})]})]}),(0,n.jsxs)("li",{className:"flex",children:[(0,n.jsx)("svg",{className:"h-6 w-6 text-primary mr-2 flex-shrink-0",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z",clipRule:"evenodd"})}),(0,n.jsxs)("div",{children:[(0,n.jsx)("p",{className:"font-bold",children:"Planning and sequential decision-making"}),(0,n.jsx)("p",{className:"text-gray-700",children:"Breaking down complex tasks into sequences of actions, enabling more sophisticated goal-directed behavior"})]})]}),(0,n.jsxs)("li",{className:"flex",children:[(0,n.jsx)("svg",{className:"h-6 w-6 text-primary mr-2 flex-shrink-0",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z",clipRule:"evenodd"})}),(0,n.jsxs)("div",{children:[(0,n.jsx)("p",{className:"font-bold",children:"Memory systems"}),(0,n.jsx)("p",{className:"text-gray-700",children:"Augmenting LLMs with external memory to maintain context over extended periods and store relevant information"})]})]}),(0,n.jsxs)("li",{className:"flex",children:[(0,n.jsx)("svg",{className:"h-6 w-6 text-primary mr-2 flex-shrink-0",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z",clipRule:"evenodd"})}),(0,n.jsxs)("div",{children:[(0,n.jsx)("p",{className:"font-bold",children:"Tool use"}),(0,n.jsx)("p",{className:"text-gray-700",children:"Integrating LLMs with specialized tools and APIs, allowing them to perform specific actions or access external information"})]})]}),(0,n.jsxs)("li",{className:"flex",children:[(0,n.jsx)("svg",{className:"h-6 w-6 text-primary mr-2 flex-shrink-0",fill:"currentColor",viewBox:"0 0 20 20",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M10 18a8 8 0 100-16 8 8 0 000 16zm3.707-9.293a1 1 0 00-1.414-1.414L9 10.586 7.707 9.293a1 1 0 00-1.414 1.414l2 2a1 1 0 001.414 0l4-4z",clipRule:"evenodd"})}),(0,n.jsxs)("div",{children:[(0,n.jsx)("p",{className:"font-bold",children:"Feedback mechanisms"}),(0,n.jsx)("p",{className:"text-gray-700",children:"Learning from the outcomes of actions, improving decision-making over time"})]})]})]})]}),(0,n.jsxs)("div",{children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-4 text-primary",children:"Advantages of LLM-Powered Agents"}),(0,n.jsxs)("div",{className:"space-y-4",children:[(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h5",{className:"font-bold text-primary mb-2",children:"More Flexible Reasoning"}),(0,n.jsx)("p",{children:"LLMs can handle a wider range of situations and adapt to novel contexts without explicit programming, making them ideal for dynamic environmental applications."})]}),(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h5",{className:"font-bold text-secondary mb-2",children:"Better Handling of Uncertainty"}),(0,n.jsx)("p",{children:"LLMs can reason effectively with incomplete or ambiguous information, a common challenge in environmental monitoring."})]}),(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h5",{className:"font-bold text-accent mb-2",children:"Improved Human-Agent Interaction"}),(0,n.jsx)("p",{children:"Natural language capabilities facilitate more intuitive communication with human operators, essential for collaborative environmental management."})]}),(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h5",{className:"font-bold text-green-600 mb-2",children:"World Knowledge"}),(0,n.jsx)("p",{children:"LLMs bring broad knowledge acquired during training, reducing the need for domain-specific programming in environmental applications."})]})]})]})]}),(0,n.jsxs)("div",{className:"bg-secondary text-white p-6 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-4",children:"Limitations and Challenges"}),(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-2 gap-4",children:[(0,n.jsxs)("div",{className:"border-l-4 border-white pl-4",children:[(0,n.jsx)("h5",{className:"font-bold mb-2",children:"Hallucination and Factual Accuracy"}),(0,n.jsx)("p",{children:"LLMs may generate plausible but incorrect information, particularly problematic for environmental decision-making."})]}),(0,n.jsxs)("div",{className:"border-l-4 border-white pl-4",children:[(0,n.jsx)("h5",{className:"font-bold mb-2",children:"Computational Requirements"}),(0,n.jsx)("p",{children:"Running sophisticated LLMs requires significant computational resources, challenging for field deployment in environmental monitoring."})]}),(0,n.jsxs)("div",{className:"border-l-4 border-white pl-4",children:[(0,n.jsx)("h5",{className:"font-bold mb-2",children:"Explainability Challenges"}),(0,n.jsx)("p",{children:"The reasoning processes of LLMs are often opaque, making it difficult to understand how environmental decisions are made."})]}),(0,n.jsxs)("div",{className:"border-l-4 border-white pl-4",children:[(0,n.jsx)("h5",{className:"font-bold mb-2",children:"Training Data Biases"}),(0,n.jsx)("p",{children:"LLMs may reflect biases present in their training data, potentially leading to unfair or inappropriate environmental decisions."})]})]})]})]})}),(0,n.jsx)("section",{id:"architecture",className:"py-16 bg-gray-100",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-8 text-primary",children:"LLM-Powered Agent Architecture"}),(0,n.jsxs)("div",{className:"bg-white p-8 rounded-lg shadow-md mb-8",children:[(0,n.jsx)("h3",{className:"text-2xl font-heading font-bold mb-6 text-primary",children:"Typical Architecture Components"}),(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-3 gap-6 mb-8",children:[(0,n.jsx)("div",{className:"col-span-1 md:col-span-3",children:(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md mb-6",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-2 text-primary",children:"1. Input Processing"}),(0,n.jsx)("p",{children:"Converting perceptual information from various sources (sensors, databases, user instructions) into a format the LLM can process."})]})}),(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-2 text-secondary",children:"2. Context Management"}),(0,n.jsx)("p",{children:"Maintaining relevant information about the current state, history, and objectives to provide the LLM with necessary context."})]}),(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-2 text-secondary",children:"3. LLM Reasoning"}),(0,n.jsx)("p",{children:"Using the LLM to interpret the current situation, generate potential actions, and evaluate their likely outcomes."})]}),(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-2 text-secondary",children:"4. Action Selection"}),(0,n.jsx)("p",{children:"Choosing the most appropriate action based on the LLM's reasoning and any additional constraints or policies."})]}),(0,n.jsx)("div",{className:"col-span-1 md:col-span-3",children:(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md mb-6",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-2 text-primary",children:"5. Execution"}),(0,n.jsx)("p",{children:"Carrying out the selected action through appropriate interfaces or effectors."})]})}),(0,n.jsx)("div",{className:"col-span-1 md:col-span-3",children:(0,n.jsxs)("div",{className:"bg-gray-100 p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"text-xl font-heading font-bold mb-2 text-primary",children:"6. Feedback Integration"}),(0,n.jsx)("p",{children:"Observing the results of actions and incorporating this information into future reasoning."})]})})]}),(0,n.jsx)("p",{className:"text-lg",children:"This architecture enables more flexible and sophisticated agent behavior compared to traditional approaches, particularly in domains that require complex reasoning, adaptation to novel situations, or natural interaction with humans—all critical capabilities for environmental monitoring and resource optimization applications."})]}),(0,n.jsxs)("div",{className:"bg-primary text-white p-6 rounded-lg shadow-md mb-8",children:[(0,n.jsx)("h3",{className:"text-2xl font-heading font-bold mb-4",children:"Environmental Application Example"}),(0,n.jsx)("p",{className:"mb-4",children:"In an environmental monitoring context, this architecture might be implemented as follows:"}),(0,n.jsxs)("ol",{className:"space-y-3 pl-6 list-decimal",children:[(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Input Processing:"})," Sensor data from air quality monitors, weather stations, and satellite imagery is collected and formatted for the LLM."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Context Management:"})," Historical air quality trends, seasonal patterns, and regulatory thresholds are maintained as context."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"LLM Reasoning:"})," The LLM analyzes current air quality readings in context, identifies potential pollution sources, and predicts future air quality."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Action Selection:"})," Based on the analysis, the agent selects appropriate actions, such as adjusting monitoring frequency, issuing alerts, or recommending traffic restrictions."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Execution:"})," The selected actions are implemented through the appropriate systems (e.g., sensor network controls, alert systems, traffic management interfaces)."]}),(0,n.jsxs)("li",{children:[(0,n.jsx)("span",{className:"font-bold",children:"Feedback Integration:"})," The effectiveness of the actions is monitored, and this information is used to improve future decision-making."]})]})]}),(0,n.jsxs)("div",{className:"flex flex-col md:flex-row gap-8",children:[(0,n.jsxs)("div",{className:"md:w-1/2",children:[(0,n.jsx)("h3",{className:"text-2xl font-heading font-bold mb-6 text-primary",children:"Implementation Frameworks"}),(0,n.jsx)("p",{className:"text-lg mb-4",children:"Several frameworks have emerged to facilitate the development of LLM-powered agents:"}),(0,n.jsxs)("ul",{className:"space-y-3",children:[(0,n.jsxs)("li",{className:"bg-white p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"font-bold text-primary",children:"LangChain"}),(0,n.jsx)("p",{children:"A framework for developing applications powered by language models, with components for agent construction, memory, and tool use."})]}),(0,n.jsxs)("li",{className:"bg-white p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"font-bold text-secondary",children:"AutoGPT"}),(0,n.jsx)("p",{children:"An experimental open-source application that demonstrates the potential of GPT-4 in an agentic setting with autonomous goal pursuit."})]}),(0,n.jsxs)("li",{className:"bg-white p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"font-bold text-accent",children:"CrewAI"}),(0,n.jsx)("p",{children:"A framework for orchestrating role-playing autonomous AI agents, enabling collaborative problem-solving among specialized agents."})]}),(0,n.jsxs)("li",{className:"bg-white p-4 rounded-lg shadow-md",children:[(0,n.jsx)("h4",{className:"font-bold text-green-600",children:"Microsoft Semantic Kernel"}),(0,n.jsx)("p",{children:"An SDK that integrates LLMs with conventional programming languages, enabling the creation of AI agents with access to external tools."})]})]})]}),(0,n.jsxs)("div",{className:"md:w-1/2",children:[(0,n.jsx)("h3",{className:"text-2xl font-heading font-bold mb-6 text-primary",children:"Future Directions"}),(0,n.jsxs)("div",{className:"bg-white p-6 rounded-lg shadow-md",children:[(0,n.jsx)("p",{className:"text-lg mb-4",children:"The field of LLM-powered agents is rapidly evolving, with several promising directions for environmental applications:"}),(0,n.jsxs)("ul",{className:"space-y-3 list-disc pl-6",children:[(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Multimodal agents"})," that can process and reason about visual and audio data alongside text, enabling more comprehensive environmental monitoring."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Domain-specific fine-tuning"})," of LLMs for environmental applications, improving accuracy and reducing hallucinations in specialized contexts."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Edge-deployable LLMs"})," that can run on resource-constrained devices in the field, enabling intelligent monitoring in remote locations."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Explainable agent architectures"})," that provide transparent reasoning processes, critical for building trust in environmental decision-making."]}),(0,n.jsxs)("li",{className:"text-lg",children:[(0,n.jsx)("span",{className:"font-bold text-primary",children:"Collaborative human-agent frameworks"})," that leverage the complementary strengths of humans and AI for environmental stewardship."]})]})]})]})]})]})}),(0,n.jsx)("section",{className:"py-12 bg-secondary text-white",children:(0,n.jsxs)("div",{className:"container mx-auto px-4 text-center",children:[(0,n.jsx)("h2",{className:"text-3xl font-heading font-bold mb-6",children:"Continue Exploring"}),(0,n.jsxs)("div",{className:"flex flex-col md:flex-row justify-center gap-6",children:[(0,n.jsx)(r(),{href:"/monitoring",className:"bg-white text-secondary hover:bg-accent hover:text-white font-bold py-3 px-8 rounded-lg shadow-lg transition duration-300",children:"Environmental Monitoring Applications →"}),(0,n.jsx)(r(),{href:"/optimization",className:"bg-white text-secondary hover:bg-accent hover:text-white font-bold py-3 px-8 rounded-lg shadow-lg transition duration-300",children:"Resource Optimization Applications →"})]})]})})]}),(0,n.jsx)("footer",{className:"bg-gray-800 text-white py-12",children:(0,n.jsxs)("div",{className:"container mx-auto px-4",children:[(0,n.jsxs)("div",{className:"grid grid-cols-1 md:grid-cols-4 gap-8",children:[(0,n.jsxs)("div",{children:[(0,n.jsx)("h3",{className:"text-xl font-heading font-bold mb-4",children:"AI Agents for Sustainability"}),(0,n.jsx)("p",{className:"text-gray-300",children:"An interactive resource on autonomous AI agents for environmental monitoring and resource optimization."})]}),(0,n.jsxs)("div",{children:[(0,n.jsx)("h4",{className:"text-lg font-heading font-bold mb-4",children:"Quick Links"}),(0,n.jsxs)("ul",{className:"space-y-2",children:[(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/",className:"text-gray-300 hover:text-accent",children:"Home"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/about",className:"text-gray-300 hover:text-accent",children:"About"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/resources",className:"text-gray-300 hover:text-accent",children:"Resources"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/contact",className:"text-gray-300 hover:text-accent",children:"Contact"})})]})]}),(0,n.jsxs)("div",{children:[(0,n.jsx)("h4",{className:"text-lg font-heading font-bold mb-4",children:"Topics"}),(0,n.jsxs)("ul",{className:"space-y-2",children:[(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/foundations",className:"text-gray-300 hover:text-accent",children:"Agent AI Foundations"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/monitoring",className:"text-gray-300 hover:text-accent",children:"Environmental Monitoring"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/optimization",className:"text-gray-300 hover:text-accent",children:"Resource Optimization"})}),(0,n.jsx)("li",{children:(0,n.jsx)(r(),{href:"/future",className:"text-gray-300 hover:text-accent",children:"Future Directions"})})]})]}),(0,n.jsxs)("div",{children:[(0,n.jsx)("h4",{className:"text-lg font-heading font-bold mb-4",children:"Connect"}),(0,n.jsx)("p",{className:"text-gray-300 mb-4",children:"Stay updated with the latest in AI for sustainability."}),(0,n.jsxs)("div",{className:"flex space-x-4",children:[(0,n.jsx)("a",{href:"#",className:"text-gray-300 hover:text-accent",children:(0,n.jsx)("svg",{className:"h-6 w-6",fill:"currentColor",viewBox:"0 0 24 24","aria-hidden":"true",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M22 12c0-5.523-4.477-10-10-10S2 6.477 2 12c0 4.991 3.657 9.128 8.438 9.878v-6.987h-2.54V12h2.54V9.797c0-2.506 1.492-3.89 3.777-3.89 1.094 0 2.238.195 2.238.195v2.46h-1.26c-1.243 0-1.63.771-1.63 1.562V12h2.773l-.443 2.89h-2.33v6.988C18.343 21.128 22 16.991 22 12z",clipRule:"evenodd"})})}),(0,n.jsx)("a",{href:"#",className:"text-gray-300 hover:text-accent",children:(0,n.jsx)("svg",{className:"h-6 w-6",fill:"currentColor",viewBox:"0 0 24 24","aria-hidden":"true",children:(0,n.jsx)("path",{d:"M8.29 20.251c7.547 0 11.675-6.253 11.675-11.675 0-.178 0-.355-.012-.53A8.348 8.348 0 0022 5.92a8.19 8.19 0 01-2.357.646 4.118 4.118 0 001.804-2.27 8.224 8.224 0 01-2.605.996 4.107 4.107 0 00-6.993 3.743 11.65 11.65 0 01-8.457-4.287 4.106 4.106 0 001.27 5.477A4.072 4.072 0 012.8 9.713v.052a4.105 4.105 0 003.292 4.022 4.095 4.095 0 01-1.853.07 4.108 4.108 0 003.834 2.85A8.233 8.233 0 012 18.407a11.616 11.616 0 006.29 1.84"})})}),(0,n.jsx)("a",{href:"#",className:"text-gray-300 hover:text-accent",children:(0,n.jsx)("svg",{className:"h-6 w-6",fill:"currentColor",viewBox:"0 0 24 24","aria-hidden":"true",children:(0,n.jsx)("path",{fillRule:"evenodd",d:"M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z",clipRule:"evenodd"})})})]})]})]}),(0,n.jsx)("div",{className:"border-t border-gray-700 mt-8 pt-8 text-center text-gray-300",children:(0,n.jsx)("p",{children:"\xa9 2025 AI Agents for Sustainability. Created for ICNGT-2025 Conference."})})]})})]})}}},e=>{var s=s=>e(e.s=s);e.O(0,[695,636,593,792],()=>s(4275)),_N_E=e.O()}]);